{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e28d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score as auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mriqc_learn.datasets import load_dataset\n",
    "from mriqc_learn.models import preprocess as pp\n",
    "from mriqc_learn.models.production import init_pipeline\n",
    "from mriqc_learn.model_selection import split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1c51b72",
   "metadata": {},
   "source": [
    "## Load some data\n",
    "We first load the CHUV100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973dc0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (_, _) = load_dataset(\n",
    "    dataset=\"chuv100\",\n",
    "    split_strategy=\"none\",\n",
    "    first_iqm=\"centroid\",\n",
    ")\n",
    "#train_x[\"site\"] = train_y.site\n",
    "train_x[\"sub_ses\"] = train_y.sub_ses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f8885",
   "metadata": {},
   "source": [
    "Let's pick the ratings from \"rater_3\" and binarize the three categories into only two.\n",
    "We can also see that the dataset is unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[\"rating_avg\"] = train_y[[\"rater_1\",\"rater_2\"]].values.mean(axis=1)\n",
    "train_y[[\"rating_avg\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4ec3e",
   "metadata": {},
   "source": [
    "Let's print out a pretty view of the data table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14a5d0c0",
   "metadata": {},
   "source": [
    "## Visualization and analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8986cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mriqc_learn.viz import metrics\n",
    "from mriqc_learn.models.preprocess import SiteRobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = metrics.plot_batches(train_x,group_by=\"sub_ses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x = SiteRobustScaler(unit_variance=True, groupby=\"sub_ses\").fit_transform(train_x)\n",
    "fig2 = metrics.plot_batches(scaled_x, group_by=\"sub_ses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d53ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_correlation(corrmat, threshold=0.95, skip_nan=False, verbose=False):\n",
    "    # Select upper triangle of correlation matrix\n",
    "    if skip_nan:\n",
    "        keys_no_nan = [k for k in corrmat.columns if \"_nan\" not in k]\n",
    "        corrmat = corrmat.loc[keys_no_nan][keys_no_nan]\n",
    "    upper = corrmat.where(np.triu(np.ones(corrmat.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(abs(upper[column]) > threshold)]\n",
    "    if verbose:\n",
    "        for col in sorted(to_drop):\n",
    "            df_col = upper[col]\n",
    "            print(f\"{col} correlated with:\")\n",
    "            for k,v in df_col[abs(df_col) > threshold].items():\n",
    "                print(f\"\\t{k} ({v:.2f})\")\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13593e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order columns: features first, whether there is a nan second\n",
    "metrics = train_x.copy()\n",
    "metrics = metrics.drop(\"sub_ses\",axis=1)\n",
    "cols_nan = [col for col in metrics.columns if \"_nan\" in col]\n",
    "cols_rest = [col for col in metrics.columns if \"_nan\" not in col]\n",
    "metrics = metrics[cols_rest + cols_nan]\n",
    "\n",
    "cst_cols = metrics.columns[(metrics.var() == 0).values].tolist()\n",
    "print(\"Dropped columns (constant):\", cst_cols)\n",
    "metrics = metrics.drop(cst_cols, axis=1)\n",
    "to_drop = find_largest_correlation(metrics.corr(), threshold=0.92, skip_nan=False)\n",
    "print(\"Redundant metrics:\", to_drop)\n",
    "metrics = metrics.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c908ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lower_tri_heatmap(df, output=\"cooc_matrix.png\"):\n",
    "    mask = np.zeros_like(df, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Want diagonal elements as well\n",
    "    mask[np.diag_indices_from(mask)] = False\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns_plot = sns.heatmap(df, mask=mask, cmap=cmap, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    f.show()\n",
    "    # save to file\n",
    "    #fig = sns_plot.get_figure()\n",
    "    #fig.savefig(output)\n",
    "get_lower_tri_heatmap(metrics.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558946e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_sets = {f\"set{i+1}\": list(metrics.columns[i*10:i*10+9]) for i in range(5)}\n",
    "for metrics_set in metrics_sets.values():\n",
    "     sns.pairplot(metrics[metrics_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_histogram(train_x, scaled_x, groupby=\"sub_ses\",metric=\"centroid\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_histogram(train_x, scaled_x, groupby=\"sub_ses\",metric=\"dl_slice_iqa_full\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c76905",
   "metadata": {},
   "source": [
    "## Cross-validation of the default classifier\n",
    "Let's cross-validate the performance of our classifier using a Leave-one-site-out strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a splitting strategy\n",
    "from mriqc_learn.model_selection import split as sp\n",
    "outer_cv = sp.LeavePSitesOut(1, colname=\"sub_ses\", robust=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992f5cc",
   "metadata": {},
   "source": [
    "We can now feed the model into the cross-validation loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efb2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "model = GBR()\n",
    "\n",
    "x = train_x.drop(\"sub_ses\",axis=1)\n",
    "x = x.drop(cst_cols+to_drop,axis=1)\n",
    "y = np.array(train_y[[\"rating_avg\"]]).flatten()\n",
    "cv_score = []\n",
    "for train, test in outer_cv.split(train_x, y):\n",
    "    xtr, ytr = x.loc[train], y[train]\n",
    "    xte, yte = x.loc[test], y[test]\n",
    "    res = model.fit(xtr, ytr)\n",
    "    ypred = res.predict(xte).flatten()\n",
    "    ypred = np.clip(ypred, 1,4)\n",
    "    mae = mean_absolute_error(yte, ypred)\n",
    "    cv_score += [mae]\n",
    "print(np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce93a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ses = list(train_x[\"sub_ses\"])\n",
    "group_og = []\n",
    "group_dict = {}\n",
    "curr_group = 0\n",
    "for idx in sub_ses:\n",
    "    if idx in group_dict.keys():\n",
    "        group_og.append(idx)\n",
    "    else:\n",
    "        group_dict[idx] = curr_group\n",
    "        group_og.append(idx)\n",
    "        curr_group+=1\n",
    "group = group_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd38ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "model = GBR()\n",
    "\n",
    "x = train_x.drop(\"sub_ses\",axis=1)\n",
    "x = x.drop(cst_cols+to_drop,axis=1)\n",
    "y = np.array(train_y[[\"rating_avg\"]]).ravel()\n",
    "mae, r2 = [], []\n",
    "kf = KFold(n_splits=5)\n",
    "#groups = train_y[[\"sub_ses\"]]\n",
    "split = kf.split(train_x, train_y[[\"rating_avg\"]],group)\n",
    "for train, test in split:\n",
    "    xtr, ytr = x.loc[train], y[train]\n",
    "    xte, yte = x.loc[test], y[test]\n",
    "    g = np.array(group)\n",
    "    print(np.unique(g[train]), np.unique(g[test]))\n",
    "    clf = model.fit(xtr, ytr)\n",
    "    ypred = model.predict(xte).flatten()\n",
    "    #ypred = np.clip(ypred, 1,4)\n",
    "    mae_, r2_ = mean_absolute_error(yte, ypred), r2_score(yte, ypred)\n",
    "    mae += [mae_]\n",
    "    r2 += [r2_]\n",
    "print(f\"{clf}: MAE={np.mean(mae):.3f}, r2={np.mean(r2):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98edd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(x):\n",
    "    return (x - x.mean())/(x.std()+1e-8)\n",
    "\n",
    "norm_x = train_x.drop(\"sub_ses\",axis=1).apply(z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f61aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "cv_score = cross_val_score(\n",
    "    GradientBoostingRegressor(),\n",
    "    X=train_x.drop(\"sub_ses\",axis=1),\n",
    "    y=np.array(train_y[[\"rating_avg\"]]).flatten(),\n",
    "    groups=train_x[[\"sub_ses\"]],\n",
    "    cv=KFold(n_splits=5, shuffle=False),\n",
    "    scoring=\"r2\",   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "random_state = 432\n",
    "nsplits=5\n",
    "nrepeats = 1\n",
    "#rkf = RepeatedKFold(n_splits=nsplits, n_repeats=10,random_state=random_state)\n",
    "rkf = KFold(n_splits=nsplits, shuffle=True)\n",
    "models = [\n",
    "    GradientBoostingRegressor()\n",
    "]\n",
    "y = np.array(train_y[[\"rating_avg\"]]).ravel()\n",
    "for Xstr, x in {\"X\":train_x, \"X_norm\": scaled_x, \"X_norm2\":norm_x}.items():\n",
    "    print(f\"\\n{Xstr}\")\n",
    "    if \"sub_ses\" in  x.columns:\n",
    "        print(\"SUB_SES FOUND:\")\n",
    "        group2 = x[\"sub_ses\"]\n",
    "        x = x.drop(\"sub_ses\", axis=1)\n",
    "    else:\n",
    "        group2 = group\n",
    "        print(len(group2))\n",
    "    for clf in models:\n",
    "        out_tot[Xstr][clf] = []\n",
    "        split = rkf.split(x,y, group2)\n",
    "        mae_tot = []\n",
    "        r2_tot = []\n",
    "        \n",
    "        for i, (train, test) in enumerate(split):\n",
    "            xtr,ytr=x.loc[train], y[train]\n",
    "            xte,yte=x.loc[test], y[test]\n",
    "            \n",
    "            reg = clf.fit(xtr, ytr)\n",
    "            ypred = clf.predict(xte).flatten()\n",
    "            ypred = np.clip(ypred, 1,4)\n",
    "            \n",
    "            mae, r2 = mean_absolute_error(yte, ypred), r2_score(yte, ypred)\n",
    "            mae_tot.append(mae)\n",
    "            r2_tot.append(r2)\n",
    "        #print(mae_tot, r2_tot)\n",
    "        print(f\"{clf}: MAE={np.mean(mae_tot):.3f}+-{np.std(mae_tot):.3f}, r2={np.mean(r2_tot):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SES FOUND:\n",
    "GradientBoostingRegressor(): MAE=0.350, r2=0.562\n",
    "\n",
    "X_norm\n",
    "SUB_SES FOUND:\n",
    "GradientBoostingRegressor(): MAE=0.433, r2=0.360\n",
    "\n",
    "X_norm2\n",
    "GradientBoostingRegressor(): MAE=0.348, r2=0.564"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e4441",
   "metadata": {},
   "source": [
    "\n",
    "X\n",
    "LinearRegression(): MAE=0.664, r2=-0.665\n",
    "\tSpearman=0.472 0.0014\n",
    "Ridge(): MAE=0.401, r2=0.338\n",
    "\tSpearman=0.707 0.0000\n",
    "DecisionTreeRegressor(): MAE=0.444, r2=0.229\n",
    "\tSpearman=0.550 0.0004\n",
    "GradientBoostingRegressor(): MAE=0.357, r2=0.535\n",
    "\tSpearman=0.733 0.0000\n",
    "GradientBoostingRegressor(loss='absolute_error'): MAE=0.345, r2=0.592\n",
    "\tSpearman=0.779 0.0000\n",
    "\n",
    "X_norm\n",
    "LinearRegression(): MAE=0.979, r2=-2.159\n",
    "\tSpearman=0.087 0.5626\n",
    "Ridge(): MAE=0.832, r2=-1.342\n",
    "\tSpearman=0.072 0.2945\n",
    "DecisionTreeRegressor(): MAE=0.583, r2=-0.287\n",
    "\tSpearman=0.336 0.0260\n",
    "GradientBoostingRegressor(): MAE=0.437, r2=0.345\n",
    "\tSpearman=0.526 0.0000\n",
    "GradientBoostingRegressor(loss='absolute_error'): MAE=0.475, r2=0.284\n",
    "\tSpearman=0.473 0.0003\n",
    "\n",
    "X_norm2\n",
    "LinearRegression(): MAE=0.796, r2=-1.343\n",
    "\tSpearman=0.290 0.1752\n",
    "Ridge(): MAE=0.369, r2=0.474\n",
    "\tSpearman=0.722 0.0000\n",
    "DecisionTreeRegressor(): MAE=0.430, r2=0.310\n",
    "\tSpearman=0.619 0.0000\n",
    "GradientBoostingRegressor(): MAE=0.357, r2=0.534\n",
    "\tSpearman=0.731 0.0000\n",
    "GradientBoostingRegressor(loss='absolute_error'): MAE=0.350, r2=0.575\n",
    "\tSpearman=0.773 0.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(\n",
    "    init_pipeline(\n",
    "        model = \"gradient_boosting_regression_l1\",\n",
    "        drop_ft = False,\n",
    "        use_classifier = False,\n",
    "        groupby = \"sub_ses\",\n",
    "    ),\n",
    "    X=train_x,\n",
    "    y=np.array(train_y[[\"rating_avg\"]]).flatten(),\n",
    "    cv=outer_cv,\n",
    "    scoring=\"r2\",\n",
    "    error_score='raise'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc225b6",
   "metadata": {},
   "source": [
    "After one or two minutes, the scores have been caculated for each of the 14 folds our splitter created.\n",
    "The average performance is AUC=0.885."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a98f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f\"{x:.3f}\" for x in cv_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_score)\n",
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cv_score = {}\n",
    "for train_index, (site, test_index) in outer_cv.split(train_x, y=train_y, return_key=True):\n",
    "    # Validate on test fold\n",
    "    print(f\"Validating on left-out site ({site})...\")\n",
    "    model_split = init_pipeline()\n",
    "    model_split = model_split.fit(train_x.iloc[train_index], train_y[train_index])\n",
    "    custom_cv_score[site] = auc(train_y[test_index], model_split.predict(train_x.iloc[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_cv_score)\n",
    "np.mean(list(custom_cv_score.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622dc24",
   "metadata": {},
   "source": [
    "We now train the model on all available training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_pipeline().fit(\n",
    "    X=train_x,\n",
    "    y=train_y,\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ac340",
   "metadata": {},
   "source": [
    "We can easily see the effects of overfitting by evaluating the classifier on the same folds we used for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_cv_score = {}\n",
    "for train_index, (site, test_index) in outer_cv.split(train_x, y=train_y, return_key=True):\n",
    "    print(f\"Validating on left-out site ({site})...\")\n",
    "    overfit_cv_score[site] = auc(train_y[test_index], model.predict(train_x.iloc[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([overfit_cv_score[s] - custom_cv_score[s] for s in overfit_cv_score.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(train_y, model.predict(train_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f4292f",
   "metadata": {},
   "source": [
    "## Evaluating on held-out dataset\n",
    "We first load the held-out dataset in, and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_x, test_y), (_, _) = load_dataset(\"ds030\", split_strategy=\"none\")\n",
    "test_x[\"site\"] = test_y.site\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_ghost = test_y.has_ghost.values.astype(bool)\n",
    "test_y = test_y[[\"rater_1\"]].values.squeeze().astype(int)\n",
    "print(f\"Discard={100 * (test_y == -1).sum() / len(test_y)}\")\n",
    "print(f\"Doubtful={100 * (test_y == 0).sum() / len(test_y)}\")\n",
    "print(f\"Accept={100 * (test_y == 1).sum() / len(test_y)}\")\n",
    "test_y[test_y < 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(test_y, model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33792116",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(test_y[~has_ghost], model.predict(test_x[~has_ghost]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, model.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y[~has_ghost], model.predict(test_x[~has_ghost])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cded3e3",
   "metadata": {},
   "source": [
    "## Nested cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e57e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = [{\n",
    "    \"scale__unit_variance\": [True, False],\n",
    "    \"scale__with_centering\": [True, False],\n",
    "    \"site_pred__disable\": [False, True],\n",
    "    \"winnow__disable\": [False, True],\n",
    "    \"svc__kernel\": [\"rbf\"],\n",
    "    \"svc__C\": [10],\n",
    "    \"svc__gamma\": [0.1],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV with parameter optimization\n",
    "inner_cv = split.LeavePSitesOut(1, robust=True)\n",
    "inner_cv.get_n_splits(X=train_x, y=train_y)\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=p_grid,\n",
    "    cv=inner_cv,\n",
    "    n_jobs=30,\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "# clf.fit(train_x, y=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d007f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_score = cross_val_score(\n",
    "    clf,\n",
    "    X=train_x,\n",
    "    y=train_y,\n",
    "    cv=outer_cv,\n",
    "    scoring=\"roc_auc\",\n",
    "    verbose=10,\n",
    "    n_jobs=16,\n",
    ")\n",
    "nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd499df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fetal_brain_qc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3d518de177b7733d0d440be9300add5d17fed3ba0a2f7b2a2b7921673afc6fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
